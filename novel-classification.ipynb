{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prepare-train,-test,-and-validation-sets\" data-toc-modified-id=\"Prepare-train,-test,-and-validation-sets-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prepare train, test, and validation sets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exploratory-data-analysis-(EDA)\" data-toc-modified-id=\"Exploratory-data-analysis-(EDA)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Exploratory data analysis (EDA)</a></span></li></ul></li><li><span><a href=\"#Load-embedding\" data-toc-modified-id=\"Load-embedding-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load embedding</a></span></li><li><span><a href=\"#Prepare-features-(X)-and-labels-(Y)\" data-toc-modified-id=\"Prepare-features-(X)-and-labels-(Y)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Prepare features (X) and labels (Y)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tokenization-and-padding\" data-toc-modified-id=\"Tokenization-and-padding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tokenization and padding</a></span></li><li><span><a href=\"#Creating-an-embedding-matrix\" data-toc-modified-id=\"Creating-an-embedding-matrix-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating an embedding matrix</a></span></li><li><span><a href=\"#Encoding-the-labels\" data-toc-modified-id=\"Encoding-the-labels-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Encoding the labels</a></span></li></ul></li><li><span><a href=\"#Evaluate-different-models\" data-toc-modified-id=\"Evaluate-different-models-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluate different models</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>LSTM</a></span><ul class=\"toc-item\"><li><span><a href=\"#GloVe\" data-toc-modified-id=\"GloVe-4.0.1.1\"><span class=\"toc-item-num\">4.0.1.1&nbsp;&nbsp;</span>GloVe</a></span></li></ul></li><li><span><a href=\"#Fast-text\" data-toc-modified-id=\"Fast-text-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Fast text</a></span></li><li><span><a href=\"#GRU\" data-toc-modified-id=\"GRU-4.0.3\"><span class=\"toc-item-num\">4.0.3&nbsp;&nbsp;</span>GRU</a></span></li><li><span><a href=\"#GloVe\" data-toc-modified-id=\"GloVe-4.0.4\"><span class=\"toc-item-num\">4.0.4&nbsp;&nbsp;</span>GloVe</a></span></li><li><span><a href=\"#Fast-text\" data-toc-modified-id=\"Fast-text-4.0.5\"><span class=\"toc-item-num\">4.0.5&nbsp;&nbsp;</span>Fast text</a></span></li><li><span><a href=\"#Character-level-CNN\" data-toc-modified-id=\"Character-level-CNN-4.0.6\"><span class=\"toc-item-num\">4.0.6&nbsp;&nbsp;</span>Character-level CNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#GloVe\" data-toc-modified-id=\"GloVe-4.0.6.1\"><span class=\"toc-item-num\">4.0.6.1&nbsp;&nbsp;</span>GloVe</a></span></li><li><span><a href=\"#Fast-text\" data-toc-modified-id=\"Fast-text-4.0.6.2\"><span class=\"toc-item-num\">4.0.6.2&nbsp;&nbsp;</span>Fast text</a></span></li></ul></li></ul></li><li><span><a href=\"#Transformer-(TODO)\" data-toc-modified-id=\"Transformer-(TODO)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Transformer (TODO)</a></span></li></ul></li><li><span><a href=\"#Prepare-the-prediction\" data-toc-modified-id=\"Prepare-the-prediction-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Prepare the prediction</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Which Novel Do I Belong To?\n",
    "\n",
    "In this task, you are expected to learn a Machine Learning model that classifies a given line as belonging to one of the following 12 novels:\n",
    "\n",
    "0: alice_in_wonderland\n",
    "1: dracula\n",
    "2: dubliners\n",
    "3: great_expectations\n",
    "4: hard_times\n",
    "5: huckleberry_finn\n",
    "6: les_miserable\n",
    "7: moby_dick\n",
    "8: oliver_twist\n",
    "9: peter_pan\n",
    "10: talw_of_two_cities\n",
    "11: tom_sawyer\n",
    "\n",
    "\n",
    "Description:\n",
    "\n",
    "You are provided with a zip file (offline_challenge.zip) containing three text files - xtrain.txt, ytrain.txt, xtest.txt. Each line in xtrain.txt and xtest.txt comes from a different novel. The data has been obfuscated, however the patterns in them are preserved. The novel ids corresponding to xtrain.txt are specified in ytrain.txt. You can use these labels to train a Machine Learning model (Deep Learning preferred).\n",
    "\n",
    "With the learned model, predict the novel ids of the lines in xtest.txt (one prediction per line). As part of your submission, include\n",
    "\n",
    "a) your predictions (in the same format as ytrain.txt)\n",
    "b) Expected accuracy on the test set\n",
    "c) the source code for training and prediction (< 10MB)\n",
    "d) a brief description of your method (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D, Bidirectional\n",
    "from keras.layers import LSTM, Lambda, Bidirectional, concatenate, BatchNormalization, Embedding\n",
    "from keras.layers import Reshape, RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "import IPython\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../offline_challenge/'\n",
    "\n",
    "x_train_file = path + 'xtrain_obfuscated.txt'\n",
    "y_train_file = path + 'ytrain.txt'\n",
    "x_test_file = path + 'xtest_obfuscated.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(x_train_file) as f:\n",
    "    xtrain_obfuscated = f.read().strip().lower().split('\\n')\n",
    "    \n",
    "with open(y_train_file) as f:\n",
    "    ytrain = f.read().strip().split('\\n')\n",
    "for i in range(len(ytrain)):\n",
    "    ytrain[i] = int(ytrain[i])\n",
    "\n",
    "with open(x_test_file) as f:\n",
    "    xtest_obfuscated = f.read().strip().lower().split('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe data set appears to be imbalanced as class '0' is represented by very few data points as compared\\nto class 7 or class 6\\n\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(ytrain, bins=range(min(ytrain), max(ytrain) + 1, 1),\n",
    "              alpha=1, color=\"blue\")\n",
    "plt.xlabel(\"novel\")\n",
    "plt.ylabel(\"quantity\")\n",
    "plt.title(\"comparing number of train data in each class\")\n",
    "plt.show()\n",
    "'''\n",
    "The data set appears to be imbalanced as class '0' is represented by very few data points as compared\n",
    "to class 7 or class 6\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of train and test data distribution\n",
    "\n",
    "sentence_lengths_train = [ len(sent) for sent in xtrain_obfuscated]\n",
    "sentence_lengths_test = [ len(sent) for sent in xtest_obfuscated]\n",
    "\n",
    "plt.hist(sentence_lengths_train, bins=range(min(sentence_lengths_train), max(sentence_lengths_train) + 1, 10), \n",
    "              alpha=0.4, color=\"blue\", density=True)\n",
    "plt.hist(sentence_lengths_test, bins=range(min(sentence_lengths_test), max(sentence_lengths_test) + 1, 10),\n",
    "              alpha=0.4, color=\"red\", density=True)\n",
    "labels = ['Train',\"Test\"]\n",
    "plt.legend(labels)\n",
    "plt.xlabel(\"length of sentence\")\n",
    "plt.ylabel(\"proportion\")\n",
    "plt.title(\"comparing number of characters per sentence distribution in Train and Test\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(x_train_file) as f:\n",
    "    x_train = f.read().split('\\n')\n",
    "x_train = x_train[:-1]\n",
    "\n",
    "with open(y_train_file) as f:\n",
    "    y_train = f.read().split('\\n')\n",
    "y_train = [int(y) for y in y_train if y.isdigit()] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 26\n",
    "max_sent_len = 0\n",
    "for sent in x_train:\n",
    "    max_sent_len = max(max_sent_len, len(sent))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "y_train = y_train.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for labels\n",
    "y_train = OneHotEncoder(sparse=False).fit_transform(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot feature generation\n",
    "# MaxLen = 452. \n",
    "# Other sentences are 0 padded\n",
    "x_train_onehot = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    temp = np.zeros((max_sent_len, max_char))\n",
    "    for j in range(len(x_train[i])):\n",
    "        temp[j][ord(x_train[i][j]) - ord('a')] = 1\n",
    "    x_train_onehot.append(temp)\n",
    "    \n",
    "x_train_onehot = np.asarray(x_train_onehot)\n",
    "\n",
    "x_train_onehot = x_train_onehot.reshape((x_train_onehot.shape[0], \n",
    "                                         x_train_onehot.shape[1], \n",
    "                                         x_train_onehot.shape[2], \n",
    "                                         1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train, test, and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(x_train_file) as f:\n",
    "    x_train_all = f.read().strip().lower().split('\\n')\n",
    "    \n",
    "with open(y_train_file) as f:\n",
    "    y_train = f.read().strip().split('\\n')\n",
    "for i in range(len(ytrain)):\n",
    "    y_train[i] = int(ytrain[i])\n",
    "\n",
    "with open(x_test_file) as f:\n",
    "    x_test = f.read().strip().lower().split('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embedding\n",
    "\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "\n",
    "\n",
    "- GloVe\n",
    "- Fast text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(embedding_file):\n",
    "    embedding_dict = {}\n",
    "    with open(embedding_file) as f:\n",
    "        for line in tqdm(f):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embedding_dict[word] = np.asarray(values[1:], dtype='float32')\n",
    "    return embedding_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:35, 11409.46it/s]\n",
      "1999996it [02:52, 11590.40it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_path = '../glove.6B.300d.txt'\n",
    "#glove_path = '../glove.840B.300d.txt'\n",
    "glove_embedding = {}\n",
    "\n",
    "#fasttext_path = '../wiki-news-300d-1M.vec'\n",
    "fasttext_path = '../crawl-300d-2M.vec'\n",
    "fasttext_embedding = {}\n",
    "\n",
    "glove_embedding = get_embedding(glove_path)\n",
    "fasttext_embedding = get_embedding(fasttext_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features (X) and labels (Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_features = None\n",
    "token = text.Tokenizer(num_words=max_features, char_level=True)\n",
    "\n",
    "token.fit_on_texts(list(x_train_all) + list(x_test))\n",
    "x_train_seq = token.texts_to_sequences(x_train)\n",
    "x_valid_seq = token.texts_to_sequences(x_valid)\n",
    "x_test_seq = token.texts_to_sequences(x_test)\n",
    "\n",
    "# zero pad the sequences\n",
    "#max_sent_len = 200\n",
    "max_sent_len = max([len(sent) for sent in x_train_all])\n",
    "x_train_seq = sequence.pad_sequences(x_train_seq, maxlen=max_sent_len)\n",
    "x_valid_seq = sequence.pad_sequences(x_valid_seq, maxlen=max_sent_len)\n",
    "x_test_seq = sequence.pad_sequences(x_test_seq, maxlen=max_sent_len)\n",
    "\n",
    "word_index = token.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26010\n",
      "6503\n",
      "3000\n",
      "452\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 15 12  4  9  5 14 12 17  1  2 13 17 15 12  8  7\n",
      "  6  5  8  7 15 12  3  4 13  4  4  9 10  3 21 10  1  2  8  7 11  3 13  4\n",
      "  1  2  9 25 13 17  8  7  4  9 10  3  1  2 10  3  1  6  4  9  3  4  1  2\n",
      "  1  6  8  7  6 16  1  2  9  7  9  7  3  4 19 20  1  2  8  7 11  3 22 21\n",
      " 12 17  1  2  1  2 16 11  1  6 13  4  8  7 12 16 15 18  8  7  6  5  1  2\n",
      "  1  6  5 14  8  7  6  5  6 16  1  2  4  9  3  4  1  2  8  7  6  5  8  7\n",
      " 19 20  1  2 11  3 21 10  3  4 11  3 19 20  1  2 13 17 13  4  8  7 11  3\n",
      " 21 10  5 14 10  3 21 10  1  2  6 16  4  9  3  4  1  6  3  4  5 14 19 20\n",
      "  1  2  8  7 11  3  1  6  1  2 13  4 15 12  6  5  5 14 19 20 10  3  1  6\n",
      "  1  2 13  4  8  7 15 11  8  7  1  2 15 12  8  7  1  6 21 10  5 14  6  5\n",
      "  1  6 13  4  3  4 15 12  1  2  6  5  8  7 11  3  1  2 15 12  8  7  4  9\n",
      "  6  5 12 16  1  6  1  2  1  6  3  4 13  4  6  5  5 14 17 18 22 21  1  2\n",
      " 16 11 13  4  6  5 13 25  1  2 13 17  6 16  4  9  3  4  1  6 11  3  6 16\n",
      "  3  4  9  7  5 14  1  2 22  5 10  3  1  2  1  6  4  9  5 14  1  6 13  4\n",
      "  4  9  3  4  1  2  1  6 13  4  6  5  3  4 22  5  1  2  8  7 11  3  1  6\n",
      "  1  2  4  9  9 17  1  2  1  2 16 11  6  5  8  7  1  6  5 14 19 20  1  2\n",
      "  6  5  8  7 15 12  4  9 12 16  1  2  8  7  6  5  8  7 19 20  1  2 13  4\n",
      "  1  6  8  7  8  7  6  5  1  6 13  4  1  2 15 12  4  9  5 14]\n",
      "{'u': 1, 'h': 2, 'm': 3, 'v': 4, 'e': 5, 'l': 6, 'w': 7, 't': 8, 'i': 9, 'p': 10, 'a': 11, 'k': 12, 'q': 13, 'n': 14, 's': 15, 'r': 16, 'g': 17, 'z': 18, 'd': 19, 'f': 20, 'y': 21, 'x': 22, 'c': 23, 'o': 24, 'j': 25, 'b': 26}\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_seq))\n",
    "print(len(x_valid_seq))\n",
    "print(len(x_test_seq))\n",
    "\n",
    "print(len(x_train_seq[0]))\n",
    "\n",
    "print(x_train_seq[0])\n",
    "print(word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an embedding matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_len=300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding matrix\n",
    "def get_embedding_matrix(embedding, \n",
    "                         word_index, \n",
    "                         embedding_len=300):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_len))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 11339.49it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fasttext_embedding_matrix = get_embedding_matrix(embedding=fasttext_embedding,\n",
    "                                                 word_index=word_index,\n",
    "                                                 embedding_len=embedding_len,\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 1621.88it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_embedding_matrix = get_embedding_matrix(embedding=glove_embedding,\n",
    "                                              word_index=word_index,\n",
    "                                              embedding_len=embedding_len,\n",
    "                                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_en = np_utils.to_categorical((y_train))\n",
    "y_valid_en = np_utils.to_categorical((y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    confusion_mtx = confusion_matrix(y_test, y_pred) \n",
    "    f,ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Greens\", linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    pyplot.show()\n",
    "    \n",
    "    # save plot to file\n",
    "    #filename = sys.argv[0].split('/')[-1]\n",
    "    #pyplot.savefig(filename + '_plot.png')\n",
    "    #pyplot.close()\n",
    "    #image = imread(filename + '_plot.png')\n",
    "    #pyplot.figure(figsize=(10, 25))\n",
    "    #pyplot.imshow(image)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate different models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 12\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "\n",
    "model_dict = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\n\\nmodel.add(Embedding(len(word_index) + 1,\\n                    embedding_len,\\n                    weights=[glove_embedding_matrix],\\n                    input_length=max_sent_len,\\n                    trainable=False))\\nmodel.add(SpatialDropout1D(0.3))\\nmodel.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\\nmodel.add(Dense(64, activation='relu'))\\nmodel.add(Dropout(0.3))\\n#model.add(Dense(128, activation='relu'))\\n#model.add(Dropout(0.3))\\nmodel.add(Dense(n_classes))\\nmodel.add(Activation('softmax'))\\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\n\\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\\n\\nhistory = model.fit(x=x_train_seq, \\n                    y=y_train_en, \\n                    batch_size=batch_size, \\n                    epochs=epochs, \\n                    verbose=0, \\n                    validation_data=(x_valid_seq, y_valid_en),\\n                    callbacks=[earlystop],\\n                   )\\n\\nplot_learning_curves(history)\\n\\nmodel_dict['lstm_glove'] = model\\n\\n\""
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    embedding_len,\n",
    "                    weights=[glove_embedding_matrix],\n",
    "                    input_length=max_sent_len,\n",
    "                    trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(x=x_train_seq, \n",
    "                    y=y_train_en, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=0, \n",
    "                    validation_data=(x_valid_seq, y_valid_en),\n",
    "                    callbacks=[earlystop],\n",
    "                   )\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "model_dict['lstm_glove'] = model\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\n\\nmodel.add(Embedding(len(word_index) + 1,\\n                    embedding_len,\\n                    weights=[fasttext_embedding_matrix],\\n                    input_length=max_sent_len,\\n                    trainable=False))\\nmodel.add(SpatialDropout1D(0.3))\\nmodel.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\\nmodel.add(Dense(64, activation='relu'))\\nmodel.add(Dropout(0.3))\\n#model.add(Dense(128, activation='relu'))\\n#model.add(Dropout(0.3))\\nmodel.add(Dense(n_classes))\\nmodel.add(Activation('softmax'))\\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\n\\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\\n\\nhistory = model.fit(x=x_train_seq, \\n                    y=y_train_en, \\n                    batch_size=batch_size, \\n                    epochs=epochs, \\n                    verbose=0, \\n                    validation_data=(x_valid_seq, y_valid_en),\\n                    callbacks=[earlystop],\\n                   )\\n\\nplot_learning_curves(history)\\n\\nmodel_dict['lstm_fasttext'] = model\\n\""
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    embedding_len,\n",
    "                    weights=[fasttext_embedding_matrix],\n",
    "                    input_length=max_sent_len,\n",
    "                    trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(x=x_train_seq, \n",
    "                    y=y_train_en, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=0, \n",
    "                    validation_data=(x_valid_seq, y_valid_en),\n",
    "                    callbacks=[earlystop],\n",
    "                   )\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "model_dict['lstm_fasttext'] = model\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GloVe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     embedding_len,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_sent_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(100, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(x=x_train_seq, \n",
    "                    y=y_train_en, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=0, \n",
    "                    validation_data=(x_valid_seq, y_valid_en),\n",
    "                    callbacks=[earlystop],\n",
    "                   )\n",
    "plot_learning_curves(history)\n",
    "\n",
    "model_dict['gru_glove'] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     embedding_len,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_sent_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(100, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(x=x_train_seq, \n",
    "                    y=y_train_en, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=0, \n",
    "                    validation_data=(x_valid_seq, y_valid_en),\n",
    "                    callbacks=[earlystop],\n",
    "                   )\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "model_dict['gru_fasttext'] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character-level CNN\n",
    "\n",
    "https://www.kaggle.com/kmader/character-level-cnn-classification-with-dilations\n",
    "\n",
    "https://machinelearningmastery.com/best-practices-document-classification-deep-learning/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GloVe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1626/1626 [==============================] - 45s 28ms/step - loss: 2.3421 - acc: 0.1564 - val_loss: 2.2663 - val_acc: 0.1810\n",
      "Epoch 2/100\n",
      "1626/1626 [==============================] - 47s 29ms/step - loss: 2.2132 - acc: 0.2176 - val_loss: 2.1493 - val_acc: 0.2425\n",
      "Epoch 3/100\n",
      "1626/1626 [==============================] - 44s 27ms/step - loss: 2.1136 - acc: 0.2596 - val_loss: 2.0053 - val_acc: 0.2697\n",
      "Epoch 4/100\n",
      "1626/1626 [==============================] - 43s 27ms/step - loss: 1.9787 - acc: 0.3014 - val_loss: 1.9365 - val_acc: 0.3068\n",
      "Epoch 5/100\n",
      "1626/1626 [==============================] - 44s 27ms/step - loss: 1.8790 - acc: 0.3389 - val_loss: 1.8272 - val_acc: 0.3549\n",
      "Epoch 6/100\n",
      "1626/1626 [==============================] - 39s 24ms/step - loss: 1.8136 - acc: 0.3617 - val_loss: 1.8250 - val_acc: 0.3686\n",
      "Epoch 7/100\n",
      "1626/1626 [==============================] - 42s 26ms/step - loss: 1.8024 - acc: 0.3680 - val_loss: 1.7611 - val_acc: 0.3704\n",
      "Epoch 8/100\n",
      "1626/1626 [==============================] - 44s 27ms/step - loss: 1.7932 - acc: 0.3726 - val_loss: 1.7879 - val_acc: 0.3580\n",
      "Epoch 9/100\n",
      "1626/1626 [==============================] - 45s 28ms/step - loss: 1.7895 - acc: 0.3692 - val_loss: 1.7823 - val_acc: 0.3721\n",
      "Epoch 10/100\n",
      "1626/1626 [==============================] - 51s 31ms/step - loss: 1.7826 - acc: 0.3739 - val_loss: 1.7751 - val_acc: 0.3714\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     embedding_len,\n",
    "                     weights=[glove_embedding_matrix],\n",
    "                     input_length=max_sent_len,\n",
    "                     trainable=False))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(64,\n",
    "                 5,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128,\n",
    "                 5,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(256,\n",
    "                 5,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(x=x_train_seq, \n",
    "                    y=y_train_en, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    validation_data=(x_valid_seq, y_valid_en),\n",
    "                    callbacks=[earlystop],\n",
    "                   )\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "model_dict['1dcnn_glove'] = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fast text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "286/813 [=========>....................] - ETA: 48s - loss: 2.3618 - acc: 0.1547"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     embedding_len,\n",
    "                     weights=[fasttext_embedding_matrix],\n",
    "                     input_length=max_sent_len,\n",
    "                     trainable=False))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(64,\n",
    "                 5,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128,\n",
    "                 5,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(256,\n",
    "                 5,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(x=x_train_seq, \n",
    "                    y=y_train_en, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    validation_data=(x_valid_seq, y_valid_en),\n",
    "                    callbacks=[earlystop],\n",
    "                   )\n",
    "\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "model_dict['1dcnn_fasttext'] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer (TODO)\n",
    "\n",
    "\n",
    "https://atheros.ai/blog/text-classification-with-transformers-in-tensorflow-2\n",
    "\n",
    "https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
